{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part 1\n",
    "\n",
    "In some ways, deep neural networks have already become a huge breakthrough. In other ways, they have some shortcomings that might hold them back from becoming the \"perfect solution\" to things like the Turing Test and general intelligence. Deep neural networks have very impressive results: Image recognition with 99 percent accuracy, and winning complex games like GO or Starcraft. However, these processes require extreme lengths of training, and are made to fulfill a very specific goal. It seems perhaps a bit anticlimactic to assume that neural networks are the final answer to the AI endeavor.\n",
    "\n",
    "Perceptrons and Expert systems were promising in theory, but failed to deliver on what their creators claimed they could do. Perceptrons couldn't implement a single XOR function. Expert systems broke after more than a thousand decision trees. Deep neural networks, however, are already delivering on many fronts. As a 3d artist, I never thought I'd see real-time raytracing in 3d rendering for another 5 to 10 years. [NVIDIA has already done so](https://www.youtube.com/watch?v=N9F3z8Fl0Nc) by using a deep convolutional network to denoise a single per-pixel raytrace pass (effectively rendering photo-realistic light simulations at a stable framerate).\n",
    "\n",
    "It also begs the question: will this be the technique used from here on out? Will this be the for() loop that eliminated jumpX calls? I can see a future in which neural networks remain the king of AI solutions. It involves the introduction of faster and fancier hardware that makes google-level data crunching possible to common lay-programmers like me. However, in its current form, deep nerual networks need a lot of training to predict even a few outputs. They rely extremely on correlation and not so much on extrapolation. I think trained neural networks don't have any kind of inquisitive or creative decision making that could be attributed to anything but another complex machine. At the same time, I don't have any better ideas.\n",
    "\n",
    "# part 2\n",
    "\n",
    "## feeding forward\n",
    "\n",
    "multiply input to weights (initialized as small numbers)\n",
    "\n",
    "$\\begin{pmatrix}\n",
    "1 & 1\n",
    "\\end{pmatrix}\n",
    "\\cdot\n",
    "\\begin{pmatrix}\n",
    "0.11 & 0.12 \\\\\n",
    "0.21 & 0.08 \n",
    "\\end{pmatrix}\n",
    "\\cdot\n",
    "\\begin{pmatrix}\n",
    "0.14 \\\\\n",
    "0.15 \n",
    "\\end{pmatrix}$\n",
    "\n",
    "multiplying first and second matrix\n",
    "\n",
    "1*0.11+1*0.21 =\n",
    "\n",
    "1*0.12+1*0.08 ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "print(1*0.11+1*0.21)\n",
    "print(1*0.12+1*0.08)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we have\n",
    "\n",
    "$\\begin{pmatrix}\n",
    "0.32 & 0.2\n",
    "\\end{pmatrix}\n",
    "\\cdot\n",
    "\\begin{pmatrix}\n",
    "0.14 \\\\\n",
    "0.15 \n",
    "\\end{pmatrix}$\n",
    "\n",
    "calculates to 0.32 * .14 + 0.2 *0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0748\n"
     ]
    }
   ],
   "source": [
    "print(0.32 * .14 + 0.2 *0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## error computation\n",
    "\n",
    "using L2 error\n",
    "\n",
    ">target value: 0\n",
    "\n",
    ">what we got: 0.0748\n",
    "\n",
    ">(0 - 0.0748)^2 = 0.0056\n",
    "\n",
    "delta = -0.0748"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## back propogation\n",
    "\n",
    "with the in class example as my inspiration, the learning rate shall be .05\n",
    "\n",
    "Now we back propogate through the most recent matrix operation\n",
    "\n",
    "$\\begin{pmatrix}\n",
    "0.14 & 0.15\n",
    "\\end{pmatrix}+ .05\n",
    "\\begin{pmatrix}\n",
    "0.32 \\\\\n",
    "0.20\n",
    "\\end{pmatrix}$ * -.0748\n",
    "\n",
    "=\n",
    "\n",
    "$\\begin{pmatrix}\n",
    "0.14 & 0.15\n",
    "\\end{pmatrix}+\n",
    "\\begin{pmatrix}\n",
    "-.001197 \\\\\n",
    "-.00075\n",
    "\\end{pmatrix}$\n",
    "\n",
    "which is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.138803\n",
      "0.14925\n"
     ]
    }
   ],
   "source": [
    "print(.14 - .001197)\n",
    "print(.15 - .00075)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training images         \n",
      "\tcount: 60000         \n",
      "\tshape: (60000, 28, 28)         \n",
      "\timage data type: uint8         \n",
      "\tlabel data type: uint8\n",
      " testing images         \n",
      "\tcount: 10000         \n",
      "\tshape: (10000, 28, 28)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12fa8441c50>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.datasets import fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "##outputting the set data\n",
    "print(\n",
    "    f'training images \\\n",
    "        \\n\\tcount: {len(train_labels)} \\\n",
    "        \\n\\tshape: {train_images.shape} \\\n",
    "        \\n\\timage data type: {train_images.dtype} \\\n",
    "        \\n\\tlabel data type: {train_labels.dtype}\\n',\n",
    "    f'testing images \\\n",
    "        \\n\\tcount: {len(test_labels)} \\\n",
    "        \\n\\tshape: {test_images.shape}\\n',\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#chose this nice stiletto as a shining example\n",
    "digit_image = train_images[11]\n",
    "#display the image\n",
    "plt.imshow(digit_image, cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_65 (Dense)             (None, 1024)              803840    \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 64)                65600     \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 870,090\n",
      "Trainable params: 870,090\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "#for some reason this wouldn't compile until I re-loaded the data. not sure why\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 784)) #combines 28 by 28 graph into a single 1d vector\n",
    "test_images = test_images.reshape((10000, 784))\n",
    "\n",
    "#cast image sectors to a float value\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.astype('float32') /255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "layercake = models.Sequential()\n",
    "layercake.add(layers.Dense(1024, activation='relu', input_shape=(784,)))\n",
    "\n",
    "#got advice from a friend to use adam, dropout, and binary crossentropy. I was not dissapointed\n",
    "layercake.add(layers.Dropout(0.02))\n",
    "\n",
    "#layercake.add(layers.Flatten())\n",
    "layercake.add(layers.Dense(64, activation='relu'))\n",
    "layercake.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "layercake.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "\n",
    "layercake.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0859 - acc: 0.9658\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0636 - acc: 0.9746\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0578 - acc: 0.9767\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0544 - acc: 0.9781\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0511 - acc: 0.9795\n",
      "10000/10000 [==============================] - 1s 84us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06477573670744896, 0.9738900044441223]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layercake.fit(train_images, train_labels, epochs=5, batch_size=128)\n",
    "\n",
    "layercake.evaluate(test_images, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
